{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural audio coding for speech enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this file, AudioDec needs to installed so that the import work correctly: `pip install -e ./AudioDec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -e ./AudioDec\n",
    "# %clearml-init\n",
    "#imports\n",
    "from preprocessing.DataEncoder import DataEncoder\n",
    "from train.LatentTrainer import LatentTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate encoded dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can create the pre-encoded versions of the audio files. The following parameters are expected:\n",
    "- `noise_files`: root directory of the noise files\n",
    "- `speech_files`: root directory of the speech files\n",
    "- `encoded_mixed_files`: output directory for the pre-encoded noisy audio files\n",
    "- `encoded_speech_files`: output directory for the pre-encoded clean audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_files = './'\n",
    "speech_files = './'\n",
    "encoded_mixed_files = '/dtu/blackhole/15/203189/data/train/speech_code'\n",
    "encoded_speech_files = '/dtu/blackhole/15/203189/data/train/mixed_code'\n",
    "\n",
    "data_encoder = DataEncoder(\n",
    "    speech_files=speech_files,\n",
    "    noise_files=noise_files,\n",
    "    encoded_speech_files=encoded_speech_files,\n",
    "    encoded_mixed_files=encoded_mixed_files\n",
    ")\n",
    "data_encoder.encode_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can train the network. The following parameters are expected:\n",
    "- `model_dir`: output directory for saving the model checkpoints\n",
    "- `encoded_mixed_files`: directory containing the pre-encoded noisy audio files\n",
    "- `encoded_speech_files`: directory contaning the pre-encoded clean audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/dtu/blackhole/09/203081/saved_models/'\n",
    "trainer = LatentTrainer(\n",
    "    model_dir=model_dir,\n",
    "    data_dir = encoded_speech_files,\n",
    "    noise_dir = encoded_mixed_files)\n",
    "\n",
    "trainer.train(num_epochs = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can make predictions for a given input data. The prerequisites are the followings:\n",
    "- Downloaded weights for AudioDec autoencoder `symAD_vctk_48000_hop300/checkpoint-700000steps.pkl` (available from [AudioDec's GitHub](https://github.com/facebookresearch/AudioDec)) which is expected to placed in `./AudioDec/exp/autoencoder/symAD_vctk_48000_hop300/checkpoint-700000steps.pkl`\n",
    "- `PATH_TO_LATENT_NET_PARAMS`: path to the trained model parameters\n",
    "- `PATH_TO_INPUT`: path to an input file to be denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LATENT_NET_PARAMS = \"/Users/madiistvan/Dev/DTU/Fall23/02456-Deep-learning/Poster/Project/Neural-audio-coding-for-speech-enhancement/34 (3).pt\"\n",
    "PATH_TO_INPUT = \"x.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AudioDec.models.autoencoder.AudioDec import Generator\n",
    "from train.LatentNetwork2 import LatentNetwork\n",
    "generator = Generator()\n",
    "latent = LatentNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from AudioDec.models.autoencoder.AudioDec import Generator\n",
    "tx_steps = 700000\n",
    "encoder_checkpoint = os.path.join('./AudioDec','exp', 'autoencoder', 'symAD_vctk_48000_hop300', f\"checkpoint-{tx_steps}steps.pkl\")\n",
    "generator = Generator()\n",
    "generator.load_state_dict(torch.load(encoder_checkpoint, map_location='cpu')['model']['generator'])\n",
    "data, _ = torchaudio.load(PATH_TO_INPUT, backend=\"soundfile\")\n",
    "\n",
    "latent.load_state_dict(torch.load(PATH_TO_LATENT_NET_PARAMS, map_location=torch.device('cpu')))\n",
    "generator.eval()\n",
    "latent.eval()\n",
    "x = generator.encoder(data.unsqueeze(0))\n",
    "x = generator.projector(x)\n",
    "x, _, _ = generator.quantizer(latent(x))\n",
    "x = generator.decoder(x)\n",
    "\n",
    "torchaudio.save(\"pred.wav\", x.detach().cpu().squeeze(1), 48000)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
