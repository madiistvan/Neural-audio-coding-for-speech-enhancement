{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural audio coding for speech enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -e ./AudioDec\n",
    "# %clearml-init\n",
    "#imports\n",
    "from preprocessing.DataEncoder import DataEncoder\n",
    "from train.LatentTrainer import LatentTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate encoded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_files = './'\n",
    "speech_files = './'\n",
    "encoded_mixed_files = '/dtu/blackhole/15/203189/data/train/speech_code'\n",
    "encoded_speech_files = '/dtu/blackhole/15/203189/data/train/mixed_code'\n",
    "\n",
    "data_encoder = DataEncoder(\n",
    "    speech_files=speech_files,\n",
    "    noise_files=noise_files,\n",
    "    encoded_speech_files=encoded_speech_files,\n",
    "    encoded_mixed_files=encoded_mixed_files\n",
    ")\n",
    "data_encoder.encode_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/dtu/blackhole/09/203081/saved_models/'\n",
    "trainer = LatentTrainer(\n",
    "    model_dir=model_dir,\n",
    "    data_dir = encoded_speech_files,\n",
    "    noise_dir = encoded_mixed_files)\n",
    "\n",
    "trainer.train(num_epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AudioDec.models.autoencoder.AudioDec import Generator\n",
    "from train.LatentNetwork2 import LatentNetwork\n",
    "generator = Generator()\n",
    "latent = LatentNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from AudioDec.models.autoencoder.AudioDec import Generator\n",
    "tx_steps = 700000\n",
    "encoder_checkpoint = os.path.join('./AudioDec','exp', 'autoencoder', 'symAD_vctk_48000_hop300', f\"checkpoint-{tx_steps}steps.pkl\")\n",
    "generator = Generator()\n",
    "generator.load_state_dict(torch.load(encoder_checkpoint, map_location='cpu')['model']['generator'])\n",
    "data, _ = torchaudio.load(\"x.wav\", backend=\"soundfile\")\n",
    "\n",
    "latent.load_state_dict(torch.load(f\"/Users/madiistvan/Dev/DTU/Fall23/02456-Deep-learning/Poster/Project/Neural-audio-coding-for-speech-enhancement/34 (3).pt\", map_location=torch.device('cpu')))\n",
    "generator.eval()\n",
    "latent.eval()\n",
    "x = generator.encoder(data.unsqueeze(0))\n",
    "x = generator.projector(x)\n",
    "x, _, _ = generator.quantizer(latent(x))\n",
    "x = generator.decoder(x)\n",
    "\n",
    "torchaudio.save(\"pred.wav\", x.detach().cpu().squeeze(1), 48000)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
